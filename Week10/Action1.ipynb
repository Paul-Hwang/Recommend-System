{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1代表缺失值，找出含有缺失值的列\n",
    "col_with_missing = []\n",
    "for col in train.columns:\n",
    "    if [-1] in train[col].values:\n",
    "        col_with_missing.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.01%\n"
     ]
    }
   ],
   "source": [
    "# 找出含有缺失值的行\n",
    "row_with_missing = set()\n",
    "for col in col_with_missing:\n",
    "    for i in train[col][train[col] == -1].index:\n",
    "        row_with_missing.add(i)\n",
    "# 含缺失值的样本占总数据集的百分比\n",
    "print('%.2f%%' % (len(row_with_missing) / len(train) *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79%的行数据均有缺失值，因此不能直接删除含有缺失值的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含缺失值的分类型数据列\n",
    "col_with_missing_cat = [col for col in col_with_missing if 'cat' in col]\n",
    "# 含缺失值的连续型数据列\n",
    "col_with_missing_num = [col for col in col_with_missing if 'cat' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulhwang/anaconda3/envs/python3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/paulhwang/anaconda3/envs/python3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/paulhwang/anaconda3/envs/python3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 将分类型数据的缺失值替换为众数\n",
    "for col in col_with_missing_cat:\n",
    "    train[col][train[col] == -1] = train[col].value_counts().index[0]\n",
    "# 将连续型数据的缺失值替换为均值\n",
    "for col in col_with_missing_num:\n",
    "    train[col][train[col] == -1] = train[col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target']\n",
    "train_data = train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为GBDT和LR划分训练集\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_data, y_train, test_size=0.2)\n",
    "train_x_1, train_x_2, train_y_1, train_y_2 = train_test_split(train_x, train_y, test_size=0.5)\n",
    "# GBDT\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 100)\n",
    "gbdt.fit(train_x_1, train_y_1)\n",
    "# 对GBDT输出进行OneHot编码\n",
    "gbdt_enc = OneHotEncoder(categories='auto')\n",
    "gbdt_enc.fit(gbdt.apply(train_x_1)[:, :, 0])\n",
    "# LR训练\n",
    "gbdt_lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "gbdt_lr.fit(gbdt_enc.transform(gbdt.apply(train_x_2)[:, :, 0]), train_y_2)\n",
    "# 预测\n",
    "val = gbdt_lr.predict_proba(gbdt_enc.transform(gbdt.apply(val_x)[:, :, 0]))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_d = gbdt_lr.predict(gbdt_enc.transform(gbdt.apply(val_x)[:, :, 0]))\n",
    "score = accuracy_score(val_y, val_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbdt_lr.predict_proba(gbdt_enc.transform(gbdt.apply(test)[:, :, 0]))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NE等于预测的log loss除以background CTR的熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(Y, P):\n",
    "    sum=0.0\n",
    "    for x in map(lambda y,p:(1-y)/2*math.log(1-p)+(1+y)/2*math.log(p),Y,P):\n",
    "        sum+=x\n",
    "    return -sum/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均历史点击率\n",
    "p = y_train.mean()\n",
    "# background CTR的熵\n",
    "background_ctr_ce = -(p*math.log(p)+(1-p)*math.log(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nce = log_loss(val_y, val) / background_ctr_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Cross-Entropy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "print('Normalized Cross-Entropy: %.4f' % nce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
