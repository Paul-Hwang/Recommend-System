Thinking 1: 如何使用用户标签来指导业务（如何提升业务）    
A: 通过不同的标签算法对用户标签进行分析, 向用户推荐得分最高的N个商品    
    
Thinking 2: 如果给你一堆用户数据，没有打标签。你该如何处理（如何打标签）    
A: 使用聚类方法对用户数据进行分类, 聚类结果则是新得到的标签    
    
Thinking 3: 准确率和精确率有何不同（评估指标）    
A: 准确率计算正确预测的YES和NO与所有预测结果的比例, 精确率则是正确预测的YES与所有预测的YES的比    
    
Thinking 4: 如果你使用大众点评，想要给某个餐厅打标签。这时系统可以自动提示一些标签，你会如何设计（标签推荐）    
A: 给用户推荐大众点评最热门的的标签    
   给用户推荐该餐厅最热门的标签    
   给用户推荐他常用的标签    
   将该餐厅最热门的标签和该用户经常使用的标签加权融合, 把所得标签推荐给用户    
       
Thinking 5: 我们今天使用了10种方式来解MNIST，这些方法有何不同？你还有其他方法来解决MNIST识别问题么（分类方法）    
A:     
logistic regression    
缺点：从线性回归衍生而来，将线性的值域通过sigmoid函数压缩在（0,1）范围内，缺点同linear regression，且也是要求数据是无缺失的    
优点：有两种方式求解，精确的解析解和SGD算法估计，在要求准确性时使用解析解，在要求时间效率时使用SGD 迭代    
    
SVM    
缺点：计算代价比较大，SVM是将低维无序杂乱的数据通过核函数（RBF,poly，linear，sigmoid）映射到高维空间，通过超平面将其分开    
优点：SVM是通过支撑面做分类的，也就是说不需要计算所有的样本，高维数据中只需去少量的样本，节省了内存    
    
Naive Bayes    
缺点：这一模型适合用在文本样本上，采用了朴素贝叶斯原理假设样本间是相互独立的，因此在关联比较强的样本上效果很差    
优点：也是基于其独立的假设，概率计算大大简化，节省内存和时间    
    
Kmeans    
缺点：k需要人为设定，且该算法的复杂度很高    
优点：“近朱者赤，近墨者黑”KNN是无参数训练的模型    
    
DecisionTree    
缺点：在训练数据上比较耗时    
优点：对数据要求度最低的模型，数据可以缺失，可以是非线性的，可以是不同的类型，，最接近人类逻辑思维的模型，可解释性好    
    
LDA是一种可作为特征抽取的技术可以提高数据分析过程中的计算效率, 对于不适用与正则化的模型，可以降低因维度灾难带来的过拟合    
    
Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。    
    
XGBoost是一个树集成模型，他将K（树的个数）个树的结果进行求和，作为最终的预测值。设计和构建高度可扩展的端到端提升树系统。    
    
TPOT AutoML工具    
    
其他方法:    
random forest, gradient boost, softmax regression, 卷积神经网络等. 
